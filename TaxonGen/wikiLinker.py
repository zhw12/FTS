'''
__author__: Jiaming Shen, Hanwen Zha
__description__: use wikipedia to determine the noun phrases
__latest_updates__: 3/27/2018
Use python3, not compatible with python2
'''
import wikipedia
import re
import sys
import time
import math
import multiprocessing as mp
from collections import Counter
import argparse

from itertools import zip_longest


def grouper(iterable, n, fillvalue=None):
    args = [iter(iterable)] * n
    return zip_longest(*args, fillvalue=fillvalue)


class WikiLinker:
    """A class for Wikipedia"""
    _version = 0.2

    def __init__(self):
        None

    def save_to_file(self, res, phrases2score=None, filepath="./results.txt"):
        try:
            with open(filepath, "w") as fout:
                if phrases2score:
                    for ele in sorted(phrases2score.items(), key=lambda x: -x[1]):
                        phrase = ele[0]
                        fout.write(phrase + "\t")
                        link_res = res[phrase]
                        fout.write(str(link_res[0]) + "\t" + link_res[1] + "\t")
                        fout.write(str(ele[1]))  # add phrase score to the last column
                        fout.write("\n")
                else:
                    for phrase in res:
                        fout.write(phrase + "\t")
                        link_res = res[phrase]
                        fout.write(str(link_res[0]) + "\t" + link_res[1])
                        fout.write("\n")
        except Exception as e:
            print(e)
            import ipdb;
            ipdb.set_trace();

    def get_wiki_online(self, phrase):
        try:
            m = wikipedia.page(title=phrase, pageid=None, auto_suggest=False, redirect=True, preload=False)
            print("[{}]Directly linking phrase: {}".format(mp.current_process().name, phrase, ))
            return (3, m.original_title)
        except:
            try:
                m2 = wikipedia.page(title=phrase, pageid=None, auto_suggest=True, redirect=True, preload=False)
                print("[{}]Indirectly linking phrase: {}".format(mp.current_process().name, phrase, ))
                return (2, m2.original_title)
            except wikipedia.exceptions.DisambiguationError as e:
                options = e.options
                print("[{}]Indirectly linking phrase with ambiguity: {}".format(mp.current_process().name, phrase, ))
                return (1, re.sub("\n", " ", "|".join(options)))  # some options has "\n" in text ...
            except:
                print("[{}]Unlinkable phrase: {}".format(mp.current_process().name, phrase, ))
                return (0, "")

    def get_wiki_batch(self, phrases, save=False):
        if phrases is None:
            return {}

        res = {}
        for e in phrases:
            link_res = self.get_wiki_online(e)
            res[e] = link_res

        return res

    def get_wiki_parallel(self, phrases, phrases2score, num_workers=1, save=False,
                          savefile_path="linked_results.wiki.txt"):
        num_workers += 1
        pool = mp.Pool(processes=num_workers)

        num_lines = len(phrases)
        batch_size = math.ceil(num_lines / num_workers)
        print("batch_size: %d" % batch_size)

        results = []
        for chunk in grouper(range(num_lines), batch_size):
            start = chunk[0]
            end = start + batch_size
            results.append(pool.apply_async(self.get_wiki_batch, args=(phrases[start:end + 1], False)))

        results = [p.get() for p in results]

        res = {}
        for r in results:
            res.update(r)

        ## simple analysis
        for ele in Counter([ele[0] for ele in res.values()]).items():
            print(ele)

        if (save):
            self.save_to_file(res, phrases2score, savefile_path)


def get_phrases(phrase_file, sep="\t", first_nrow=0, threshold=0, score_first=False):
    phrases = []
    phrases2score = {}
    cnt = 0
    with open(phrase_file, "r") as fin:
        for line in fin:
            cnt += 1
            s = line.strip().split(sep)
            if score_first:
                s = [s[1], s[0]]
            phrase = re.sub(r"_", " ", s[0])
            phrases.append(phrase)
            phrases2score[phrase] = float(s[1])
            if (first_nrow != 0 and cnt > first_nrow) or float(s[1]) < threshold:
                break

    print('Done: get_phrases')
    return phrases, phrases2score


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("input_phrase_file", help="original phrase file generated by AutoPhrase")
    parser.add_argument("output_phrase_file", help="output phrase file wikiLinker")
    args = parser.parse_args()

    # phrase file, e.g. AutoPhrase.txt
    filepath = args.input_phrase_file
    output_filepath = args.output_phrase_file

    # print(filepath, output_filepath)

    phrases, phrases2score = get_phrases(filepath, sep="\t", first_nrow=0, threshold=0.7, score_first=True)
    print("Number of phrases")
    # print(phrases)

    assert set(phrases) == set(phrases2score)

    w = WikiLinker()
    start = time.time()
    w.get_wiki_parallel(phrases, phrases2score, num_workers=30, save=True, savefile_path=output_filepath)
    end = time.time()
    print("Linking %s phrases using time %s (seconds)" % (len(phrases), end - start))


if __name__ == '__main__':
    main()
